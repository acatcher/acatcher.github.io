---
layout:     post
title:      Tensorflow 2.0 05
subtitle:   Variational Autoencoder #å‰¯æ ‡é¢˜
date:       2019-11-06
author:     ASeeker
header-img: img/Weathering1.jpg
catalog: true
tags:
    - tensorflow
    - deep learning
    
---

#### ä¸ç®¡æ™´å¤©è¿˜æ˜¯é›¨å¤©ï¼Œæˆ‘åªæ˜¯æƒ³å’Œä½ ç›¸é‡ã€‚

æ–°æµ·è¯šæ–°ä½œï¼Œåˆæ˜¯ä¸€éƒ¨ä¸–ç•Œç³»çš„ä½œå“ï¼Œä»·å€¼è§‚å’Œå›åç›¸åï¼Œä¸­è§„ä¸­çŸ©å§ã€‚ã€‚ã€‚ä¸æ˜¯ç‰¹åˆ«ç‰¹åˆ«æ£’çš„é‚£ç§ ç”»é¢å’Œbgmè¿˜æ˜¯å¾ˆæ£’çš„ï¼Œæˆªå±å°±å¯åšå£çº¸    


#### VAE  


> Reference[^1] [^2] [^3] [^4] [^5] [^6]

è¿™ä¸ªVAE æäº†æˆ‘å¥½ä¹…å¥½ä¹… ç½‘ä¸Šçš„èµ„æ–™çœŸçš„æ˜¯é±¼é¾™æ··æ‚ çœ‹åŸå§‹paperçœ‹äº†5ã€6é¡µå®åœ¨çœ‹ä¸ä¸‹å»äº† çœŸæ˜¯å¥½è‰°éš¾ åŠ ä¸Šæœ€è¿‘çš„å­¦ä¹ æ•ˆç‡ã€‚ã€‚ã€‚ ç›´æ¥è‡ªé—­äº†ä¸‰å¤© ç°åœ¨ç»ˆäºç®—æ˜¯æ˜ç™½ä¸€ç‚¹äº†  
ç”¨tf2å®ç°ä¸€ä¸‹  

[è¿™ç¯‡åšå®¢](https://jaan.io/what-is-variational-autoencoder-vae-tutorial/)å¯¹è‡ªå·±çš„å¸®åŠ©æŒºå¤§çš„   

å…³äºæ™®é€šçš„AEï¼Œå¾—åˆ°ä¸€ä¸ªlatentçš„è¡¨ç¤ºï¼Œä¹Ÿæ²¡æœ‰å•¥ç”¨ï¼Œä¸èƒ½åœ¨æŸç§conditionä¸‹generateå‡ºç‰¹å®šçš„è¾“å‡ºã€‚  
VAEåšäº†ä¸€ç‚¹å‡çº§ï¼Œï¼ˆä¸è¿‡æ•ˆæœè¿˜æ˜¯è¢«ç°åœ¨çš„GANåŠæ‰“  

intuitiveçš„ç†è§£åœ¨æå®æ¯…è€å¸ˆçš„[dl](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML16.html)é‡Œè®²çš„æ˜¯ååˆ†ç²¾å½©äº†ï¼Œæ¯”å¦‚è¯´ä¸€å¼ æ»¡æœˆçš„ç…§ç‰‡ğŸŒ–å’Œä¸€å¼ å¼¦æœˆğŸŒ˜çš„ç…§ç‰‡ï¼Œå–å®ƒä»¬latent representationçš„ä¸­å€¼ï¼Œå¹¶ä¸èƒ½å¾ˆå¥½çš„è¡¨ç°å‡ºæˆ‘ä»¬æœŸæœ›å‡ºç°çš„3/4ä¸ªæœˆäº®ğŸŒ— é‚£ä¹ˆæ€ä¹ˆåŠå‘¢ï¼Œæˆ‘ä»¬å°±è¦å‡è®¾latent spaceæ˜¯ä»ä¸€ä¸ªåˆ†å¸ƒä¸­å–å‡ºæ¥çš„ï¼Œè¿™æ ·ä½¿å¾—åœ¨æ»¡æœˆå’Œå¼¦æœˆä¸­é—´çš„vectoræ—¢æƒ³trainå‡ºæ»¡æœˆåˆæƒ³trainå‡ºå¼¦æœˆï¼Œå–ä¸€ä¸ªæŠ˜ä¸­ï¼Œå°±å¯ä»¥ç”Ÿæˆå‡ºä¸€ä¸ª3/4çš„æœˆäº®äº†ã€‚  

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8ot0ese1pj313b0u0gou.jpg)

é‚£ä¹ˆï¼Œæˆ‘ä»¬å°±æƒ³è®©æˆ‘ä»¬çš„latentä¸å†ç”Ÿæˆä¸€ä¸ªå…·ä½“çš„å€¼ï¼Œè€Œæ˜¯ä¸€ä¸ªåˆ†å¸ƒï¼Œæˆ‘ä»¬ä»ä¸­å»sampleï¼Œå¾—åˆ°zã€‚ç”¨åˆ°äº†é«˜æ–¯æ··åˆçš„æ€æƒ³ã€‚ç°åœ¨çš„é—®é¢˜æ˜¯å¦‚ä½•è®¾è®¡lossã€‚  

æˆ‘ä»¬å¯ä»¥å¾—åˆ°æˆ‘ä»¬æƒ³è¦çš„`p(z,x)=p(z)*p(x|z)`, æˆ‘ä»¬å¯ä»¥ç”¨NNå»ä¼˜åŒ–`p(x\|z)`,é‚£ä¹ˆé—®é¢˜çš„å…³é”®å°±æ˜¯è¦å»æ‰¾xå¦‚ä½•æ˜ å°„åˆ°zï¼Œå°±æ˜¯`p(z|x)`çš„åˆ†å¸ƒã€‚  

ç”±è´å¶æ–¯å…¬å¼ï¼Œå¯ä»¥çŸ¥é“`p(z|x) =  p(z)*p(x|z)/p(x)`,ä½†æ˜¯p(x)éœ€è¦åœ¨æ•´ä¸ªzçš„ç©ºé—´ä¸Šè¿›è¡Œç§¯åˆ†æ‰å¯ä»¥ç®—å‡ºæ¥ï¼Œè¿™æ ·çš„ç©·ä¸¾ä»£ä»·å¤ªå¤§äº†ã€‚äºæ˜¯æˆ‘ä»¬å‡è®¾ä¸€ä¸ªåˆ†å¸ƒ`q(z|x)`å»é€¼è¿‘`p(z|x)`,hhhè¿™ä¸å°±æ˜¯æˆ‘ä»¬NNå¸¸åšçš„äº‹æƒ…å˜›ã€‚é—®é¢˜å°±å˜æˆäº†ä½¿å¾—è¿™ä¸¤ä¸ªåˆ†å¸ƒæœ€æ¥è¿‘ï¼Œä½¿`KL(q(z|x)||p(z|x))`çš„å€¼æœ€å°ã€‚å…·ä½“çš„æ¨å¯¼æˆ‘å°±ä¸å†è¿™é‡Œå†™äº†ï¼ˆæ‡’+ä¸ä¼šç”¨mdæ‰“å…¬å¼hhhï¼‰ã€‚æœ€åå¾ˆç¥å¥‡çš„æ˜¯ä¸¤é¡¹ï¼Œå’Œæˆ‘ä»¬intutiveçš„æƒ³æ³•ä¹Ÿå¾ˆä¸€è‡´ï¼Œä¸€ä¸ªæ˜¯è¦æ˜¯`p(z)`å’Œ`q(z|x)`çš„åˆ†å¸ƒæ¥è¿‘ï¼Œä¸€ä¸ªæ˜¯è¦reconstructçš„errorè¦å°ã€‚  

ä¸è¿‡è¿™é‡Œæˆ‘ä»¬ä¹Ÿçœ‹åˆ°äº†ä¸€ä¸ªé—®é¢˜ï¼Œé‚£ä½ ä¸å°±æ˜¯è®©æ‰€æœ‰çš„zéƒ½è¦æ˜¯`N(0,I)`çš„åˆ†å¸ƒäº†å—ï¼Ÿå¤§å®¶çš„zå°±éƒ½å¾ˆæ¥è¿‘äº†ã€‚ã€‚è€Œæˆ‘æ„Ÿè§‰ä¸åŒç±»å‹çš„zåº”è¯¥åˆ†çš„å¾ˆè¿œï¼Œè€Œlossé‡Œæœ‰`mean**2`è¿™ä¸€é¡¹ã€‚æˆ‘åœ¨è®­ç»ƒçš„æ—¶å€™å°±ç¢°åˆ°äº†è¿™ä¸ªé—®é¢˜ï¼ˆä¸è¿‡ä¹Ÿæœ‰å¯èƒ½æ˜¯å…¶ä»–é—®é¢˜ã€‚ã€‚ã€‚è‡ªå·±ä¹Ÿè¿˜æ˜¯ä¸ªèŒæ–°ğŸ‘¶ğŸ»ğŸ£ï¼‰ï¼Œoutputéƒ½é•¿å¾—å·®ä¸å¤šï¼Œä¹Ÿçœ‹ä¸å‡ºæ¥ä¸œè¥¿ï¼Œåé¢æŠŠkl lossçš„weighté™äº†ï¼Œæ‰trainå‡ºæ¥ã€‚[çŸ¥ä¹ä¸Šéšä¾¿æŸ¥äº†ä¸€ä¸‹](https://zhuanlan.zhihu.com/p/52676826)ï¼Œç¡®å®å­˜åœ¨ä¸€ä¸ªå«ç¼–ç åå¡Œçš„é—®é¢˜ï¼Œä¸è¿‡è¿™ç¯‡æ–‡ç« è‡ªå·±çœŸçš„æ·±ç©¶ä¸ä¸‹å»äº†ã€‚ã€‚vaeå·²ç»æŠŠè‡ªå·±æŠ˜è…¾çš„åŠæ­»  

ä¸‹é¢ä¸Šä»£ç   


```python
import tensorflow as tf
import numpy as np
from tensorflow.keras import layers
from matplotlib import pyplot as plt 

from tensorflow.keras.datasets import fashion_mnist

(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
x_train = x_train.astype(np.float32).reshape([-1,784]) / 255.

train_steps = 10000
display_step = 1000

learning_rate = 1e-3
batch_size = 128

dense1_units = 256
z_dims = 20
img_dims = 784

train_data = tf.data.Dataset.from_tensor_slices(x_train)
train_data = train_data.repeat().shuffle(10000).batch(batch_size).prefetch(1)
```

ä¸€ä¸ªencoder ä¸€ä¸ªdecoder  
zæ˜¯sampleå‡ºæ¥çš„ï¼Œå®ç°çš„æ—¶å€™ç”¨äº†ä¸€ä¸ªç®€å•çš„trickï¼Œç›´æ¥çœ‹ä»£ç å°±å¥½äº†  

```python
class VAE(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.dense0 = layers.Dense(units=dense1_units, activation=tf.nn.relu)
        self.dense1 = layers.Dense(units=dense1_units, activation=tf.nn.relu)
        self.dense21 = layers.Dense(units=z_dims)
        self.dense22 = layers.Dense(units=z_dims)
        
        self.dense3 = layers.Dense(units=dense1_units, activation=tf.nn.relu)
        self.dense4 = layers.Dense(units=dense1_units, activation=tf.nn.relu)
        self.out = layers.Dense(units=img_dims)
        
        
    def encoder(self, inputs):
        outputs = self.dense0(inputs)
        outputs = self.dense1(outputs)
        mean = self.dense21(outputs)
        var = self.dense22(outputs)
        
        return mean, var
        
        
    def decoder(self, inputs):
        outputs = self.dense3(inputs)
        outputs = self.dense4(outputs)
        outputs = self.out(outputs)
        
        return outputs
        
        
    def sample(self, mean, var):
        eps = tf.random.normal(mean.shape)
        var = (tf.exp(var)**0.5) * eps
        z = mean+var
    
        return z
        
        
    def call(self, inputs):
        mean, var = self.encoder(inputs)
        z_sample = self.sample(mean, var)
        outputs = self.decoder(z_sample)
        
        return outputs, mean, var
               
vae = VAE()
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)

def draw_img(ori_img, recon_img):
    n = 4

    origin_x = np.empty((28*n, 28*n))
    reconstr_x = np.empty((28*n, 28*n))

    ori_img = (ori_img * 255.).numpy().astype(np.uint8).reshape([-1, 28, 28])
    #recon_img = recon_img.reshape([-1, 28, 28])
    
    for i in range(n):
        for j in range(n):
            origin_x[i*28:(i+1)*28, j*28:(j+1)*28] = ori_img[i*4+j,:,:]
            reconstr_x[i*28:(i+1)*28, j*28:(j+1)*28] = recon_img[i*4+j,:,:]

    print("Original Images")     
    plt.figure(figsize=(n, n))
    plt.imshow(origin_x, origin="upper", cmap="gray")
    plt.show()

    print("Reconstructed Images")
    plt.figure(figsize=(n, n))
    plt.imshow(reconstr_x, origin="upper", cmap="gray")
    plt.show()
```

trainäº†å¥½ä¹…  æœ€åæŠŠ`klloss`çš„weightæ— å¥ˆçš„æ”¹åˆ°äº†0.1ã€‚ã€‚ã€‚ã€‚æœ€åçš„æ•ˆæœå¾ˆä¸€èˆ¬  

```python
for step, batch_x in enumerate(train_data.take(train_steps+1)):
    with tf.GradientTape() as tape:
        x_recon, mean, var = vae(batch_x)
        reconloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=batch_x, logits=x_recon))
        klloss = 0.1 * tf.reduce_mean(tf.exp(var) - (var + 1) + mean**2)
        loss = reconloss + 1. * klloss
    grads = tape.gradient(loss, vae.trainable_variables)
    optimizer.apply_gradients(grads_and_vars=zip(grads, vae.trainable_variables))

    if step % display_step == 0:
        print('step %i: loss %f, reloss %f, klloss %f' %(step, loss.numpy(), reconloss.numpy(), klloss.numpy()))
        
    
        img_recon = (tf.reshape(tf.nn.sigmoid(x_recon), [-1,28,28]).numpy() * 255.).astype(np.uint8)

        draw_img(batch_x, img_recon)

        
        
    
    
```

   step 0: loss 0.714608, reloss 0.693045, klloss 0.021563  
  Original Images



![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8osu5m42vj307506zq31.jpg)


   Reconstructed Images



![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8osuebi1pj307506zmxb.jpg)


 step 1000: loss 0.385244, reloss 0.347702, klloss 0.037542



 step 2000: loss 0.370257, reloss 0.328157, klloss 0.042100



 step 3000: loss 0.365704, reloss 0.324734, klloss 0.040970



 step 4000: loss 0.373777, reloss 0.330440, klloss 0.043337



 step 5000: loss 0.375169, reloss 0.333341, klloss 0.041828


 step 6000: loss 0.374485, reloss 0.332791, klloss 0.041694



 step 7000: loss 0.353559, reloss 0.310435, klloss 0.043124



 step 8000: loss 0.370547, reloss 0.325082, klloss 0.045465



 step 9000: loss 0.372162, reloss 0.328155, klloss 0.044007



   step 10000: loss 0.370595, reloss 0.326418, klloss 0.044176  
   Original Images



![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8osulcoqxj307506zaa4.jpg)


 Reconstructed Images



![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8osur257qj307506z74e.jpg)





vaeçš„æ•ˆæœä¸€èˆ¬ï¼Œå¸ƒå‰å²›æ˜¯ä¸æ˜¯è‡ªå·±çš„å®ç°å“ªé‡Œæœ‰ç‚¹é—®é¢˜  

vaeçœŸçš„æ˜¯å¤ªéš¾trainäº†ï¼ğŸ˜­ğŸ˜­


----

[^1]: https://jaan.io/what-is-variational-autoencoder-vae-tutorial/
[^2]: https://zhuanlan.zhihu.com/p/52676826
[^3]: https://zhuanlan.zhihu.com/p/55557709
[^4]: https://zhuanlan.zhihu.com/p/33194849
[^5]: https://github.com/altosaar/variational-autoencoder/blob/master/train_variational_autoencoder_tensorflow.py
[^6]: http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML16.html






